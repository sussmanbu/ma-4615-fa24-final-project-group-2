[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "This comes from the file data.qmd.\nYour first steps in this project will be to find data to work on.\nI recommend trying to find data that interests you and that you are knowledgeable about. A bad example would be if you have no interest in video games but your data set is about video games. I also recommend finding data that is related to current events, social justice, and other areas that have an impact.\nInitially, you will study one dataset but later you will need to combine that data with another dataset. For this reason, I recommend finding data that has some date and/or location components. These types of data are conducive to interesting visualizations and analysis and you can also combine this data with other data that also has a date or location variable. Data from the census, weather data, economic data, are all relatively easy to combine with other data with time/location components."
  },
  {
    "objectID": "data.html#what-makes-a-good-data-set",
    "href": "data.html#what-makes-a-good-data-set",
    "title": "Data",
    "section": "What makes a good data set?",
    "text": "What makes a good data set?\n\nData you are interested in and care about.\nData where there are a lot of potential questions that you can explore.\nA data set that isn’t completely cleaned already.\nMultiple sources for data that you can combine.\nSome type of time and/or location component."
  },
  {
    "objectID": "data.html#where-to-keep-data",
    "href": "data.html#where-to-keep-data",
    "title": "Data",
    "section": "Where to keep data?",
    "text": "Where to keep data?\nBelow 50mb: In dataset folder\nAbove 50mb: In dataset_ignore folder. This folder will be ignored by git so you’ll have to manually sync these files across your team.\n\nSharing your data\nFor small datasets (&lt;50mb), you can use the dataset folder that is tracked by github. Add the files just like you would any other file.\nIf you create a folder named data this will cause problems.\nFor larger datasets, you’ll need to create a new folder in the project root directory named dataset-ignore. This will be ignored by git (based off the .gitignore file in the project root directory) which will help you avoid issues with Github’s size limits. Your team will have to manually make sure the data files in dataset-ignore are synced across team members.\nYour load_and_clean_data.R file is how you will load and clean your data. Here is a an example of a very simple one.\n\nsource(\n  \"scripts/load_and_clean_data.R\",\n  echo = TRUE # Use echo=FALSE or omit it to avoid code output  \n)\n\n\n&gt; library(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n&gt; library(dplyr)\n\n&gt; traffic_data &lt;- read_csv(here::here(\"dataset\", \"Traffic stops in Rhode Island.csv\"))\n\n\nRows: 91741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): state, driver_gender, driver_race, violation_raw, violation, searc...\nlgl  (4): county_name, search_conducted, is_arrested, drugs_related_stop\ndate (1): stop_date\ntime (1): stop_time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n&gt; traffic_data_cleaned &lt;- traffic_data %&gt;% filter(!is.na(driver_race) & \n+     !is.na(driver_gender) & !is.na(violation_raw) & !is.na(violation) & \n+  .... [TRUNCATED] \n\n&gt; traffic_data_cleaned$stop_time &lt;- as.numeric(traffic_data_cleaned$stop_time)\n\n&gt; secs_to_time_of_day &lt;- function(seconds) {\n+     hours &lt;- (seconds%/%3600)%%24\n+     minutes &lt;- (seconds%/%60)%%60\n+     secs &lt;- seconds%%60\n+     s .... [TRUNCATED] \n\n&gt; traffic_data_cleaned$stop_time &lt;- sapply(traffic_data_cleaned$stop_time, \n+     secs_to_time_of_day)\n\n&gt; saveRDS(traffic_data_cleaned, here::here(\"dataset\", \n+     \"cleaned_dataset.rds\"))\n\n\nYou should never use absolute paths (eg. /Users/danielsussman/path/to/project/ or C:\\MA415\\\\Final_Project\\).\nYou might consider using the here function from the here package to avoid path problems.\n\n\nLoad and clean data script\nThe idea behind this file is that someone coming to your website could largely replicate your analyses after running this script on the original data sets to clean them. This file might create a derivative data set that you then use for your subsequent analysis. Note that you don’t need to run this script from every post/page. Instead, you can load in the results of this script, which could be plain text files or .RData files. In your data page you’ll describe how these results were created. If you have a very large data set, you might save smaller data sets that you can use for exploration purposes. To link to this file, you can use [cleaning script](/scripts/load_and_clean_data.R) wich appears as cleaning script."
  },
  {
    "objectID": "data.html#rubric-on-this-page",
    "href": "data.html#rubric-on-this-page",
    "title": "Data",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nDescribe where/how to find data.\n\nYou must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.\nWhy was the data collected/curated? Who put it together? (This is important, if you don’t know why it was collected then that might not be a good dataset to look at.\n\nDescribe the different data files used and what each variable means.\n\nIf you have many variables then only describe the most relevant ones and summarize the rest.\n\nDescribe any cleaning you had to do for your data.\n\nYou must include a link to your load_and_clean_data.R file.\nRrename variables and recode factors to make data more clear.\nAlso, describe any additional R packages you used outside of those covered in class.\nDescribe and show code for how you combined multiple data files and any cleaning that was necessary for that.\nSome repetition of what you do in your load_and_clean_data.R file is fine and encouraged if it helps explain what you did.\n\nOrganization, clarity, cleanliness of the page\n\nMake sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.\nThis page should be self-contained.\n\n\n—-Response start here—-\nThe dataset had 15 variables: state, stop_date, stop_time, county_name, driver_gender, driver_race, violation_description, violation, search_conducted, search_type, stop_outcome, is_arrested, stop_duration, drugs_related_stop, and district. This data set only focused on Rhode Island so the state was irrelevant. Stop_date and stop_time stated the date and time of day that the traffic stop occurred. The county_name was an empty column, so we simply removed it for our cleaned dataset. Driver_gender and driver_race detailed the gender and race of the driver who was stopped. The variable violation gave a general classification for the violation while violation_description gave a more detailed description of the reason for the traffic stop. Search_conducted (boolean), search_type, stop_outcome, is_arrested (boolean), stop_duration, drugs_related_stop (boolean) gave more details as to what occurred during the traffic stop which gives us a better idea for the severity of the traffic violation.\nEach row in the dataset corresponds to a particular traffic stop incident, and records data for the traffic stop according to the variables listed above. Our data cleaning, visualization, and initial analysis will be as follows:\nTo clean the dataset for analysis, our first step was to remove all rows that are missing values for our vairables of focus (the following is a chunk from load_and_clean_data.R):\n\n# Removing empty rows from the dataset\ntraffic_data %&gt;%\n  filter(!is.na(driver_race) & \n           !is.na(driver_gender) & \n           !is.na(violation_raw) & \n           !is.na(violation) & \n           !is.na(search_conducted) & \n           !is.na(stop_outcome) & \n           !is.na(stop_duration) & \n           !is.na(drugs_related_stop)) %&gt;%\n  select(-state, -county_name)\n\nNext, we converted the stop_time variable, which was previously recorded as the number of seconds past 12:00am at which the stop occured, into a more readable format. To do this, we simpy apply a function which will convert seconds into the form hour:minute:second in military time (can also be found inload_and_clean_data.R):\n\nsecs_to_time_of_day &lt;- function(seconds) {\n  hours &lt;- (seconds %/% 3600) %% 24\n  minutes &lt;- (seconds %/% 60) %% 60\n  secs &lt;- seconds %% 60\n  sprintf(\"%02d:%02d:%02d\", hours, minutes, secs)\n}\n\ntraffic_data_cleaned$stop_time &lt;- as.numeric(traffic_data_cleaned$stop_time)\n# Function to convert sec to time of day\ntraffic_data_cleaned$stop_time &lt;- sapply(traffic_data_cleaned$stop_time, secs_to_time_of_day)\n\nThe following graphs and tables show a brief visual summary of the distribution of traffic stops across race. Although we can see that the distribution may be skewed by the population proportions for each race, we can see that whites are stopped most frequently, then blacks, then hispanics, then asians.\n\nsource(\n  \"scripts/eda_traffic_data.R\",\n  echo = F  \n)\n\ntibble [86,536 × 13] (S3: tbl_df/tbl/data.frame)\n $ stop_date         : Date[1:86536], format: \"2005-01-04\" \"2005-01-23\" ...\n $ stop_time         : chr [1:86536] \"12:55:00\" \"23:15:00\" \"04:15:00\" \"17:15:00\" ...\n $ driver_gender     : chr [1:86536] \"M\" \"M\" \"M\" \"M\" ...\n $ driver_race       : chr [1:86536] \"White\" \"White\" \"White\" \"White\" ...\n $ violation_raw     : chr [1:86536] \"Equipment/Inspection Violation\" \"Speeding\" \"Speeding\" \"Call for Service\" ...\n $ violation         : chr [1:86536] \"Equipment\" \"Speeding\" \"Speeding\" \"Other\" ...\n $ search_conducted  : logi [1:86536] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ search_type       : chr [1:86536] NA NA NA NA ...\n $ stop_outcome      : chr [1:86536] \"Citation\" \"Citation\" \"Citation\" \"Arrest Driver\" ...\n $ is_arrested       : logi [1:86536] FALSE FALSE FALSE TRUE FALSE FALSE ...\n $ stop_duration     : chr [1:86536] \"0-15 Min\" \"0-15 Min\" \"0-15 Min\" \"16-30 Min\" ...\n $ drugs_related_stop: logi [1:86536] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ district          : chr [1:86536] \"Zone X4\" \"Zone K3\" \"Zone X4\" \"Zone X1\" ...\nNULL\n   stop_date           stop_time         driver_gender      driver_race       \n Min.   :2005-01-04   Length:86536       Length:86536       Length:86536      \n 1st Qu.:2008-01-05   Class :character   Class :character   Class :character  \n Median :2010-11-11   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2010-10-05                                                           \n 3rd Qu.:2013-05-11                                                           \n Max.   :2015-12-31                                                           \n violation_raw       violation         search_conducted search_type       \n Length:86536       Length:86536       Mode :logical    Length:86536      \n Class :character   Class :character   FALSE:83229      Class :character  \n Mode  :character   Mode  :character   TRUE :3307       Mode  :character  \n                                                                          \n                                                                          \n                                                                          \n stop_outcome       is_arrested     stop_duration      drugs_related_stop\n Length:86536       Mode :logical   Length:86536       Mode :logical     \n Class :character   FALSE:83458     Class :character   FALSE:85674       \n Mode  :character   TRUE :3078      Mode  :character   TRUE :862         \n                                                                         \n                                                                         \n                                                                         \n   district        \n Length:86536      \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nFirst, we will visualize the distribution of key variables (e.g., ‘race’)\n\nprint(plot1)\n\n\n\n\n\n\n\nprint(plot2)\n\n\n\n\n\n\n\nprint(plot3)\n\n\n\n\n\n\n\n\nHere, we can see stopped drivers are most frequently white, then black, then hispanic, then asian. Among each race, it seems citations are the most likeley outcome, then warning, then arrest. It seems the driver is arrested more frequently for Blacks and Hispanics then other races. In addition, the frequency of traffic stops over time seems roughly constant, with a spike around 2013."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd.\nWe describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.\nThe style of this paper should aim to be that of an academic paper. I don’t expect this to be of publication quality but you should keep that aim in mind. Avoid using “we” too frequently, for example “We also found that …”. Describe your methodology and your findings but don’t describe your whole process."
  },
  {
    "objectID": "analysis.html#note-on-attribution",
    "href": "analysis.html#note-on-attribution",
    "title": "Analysis",
    "section": "Note on Attribution",
    "text": "Note on Attribution\nIn general, you should try to provide links to relevant resources, especially those that helped you. You don’t have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don’t need a formal citation.\nIf you are directly quoting from a source, please make that clear. You can show quotes using &gt; like this\n&gt; To be or not to be.\n\nTo be or not to be."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained, i.e. provide a description of the relevant data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Final Project due May 7, 2024 at 11:59pm.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSixth Post\n\n\n\n\n\nThis post details our EDA of San Fransicso data\n\n\n\n\n\nNov 18, 2024\n\n\nGroup 2\n\n\n\n\n\n\n\n\n\n\n\n\nFifth Post\n\n\n\n\n\nThis post details our incorportation of other data\n\n\n\n\n\nNov 11, 2024\n\n\nGroup 2\n\n\n\n\n\n\n\n\n\n\n\n\nFourth Post\n\n\n\n\n\nThis post details our linear regression model\n\n\n\n\n\nNov 4, 2024\n\n\nGroup 2\n\n\n\n\n\n\n\n\n\n\n\n\nThird Post\n\n\n\n\n\nThis post details our drafting of data.qmd and initial analysis\n\n\n\n\n\nOct 25, 2024\n\n\nGroup 2\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nThis post details our dataset seleciton and data cleaning\n\n\n\n\n\nOct 18, 2024\n\n\nGroup 2\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Post\n\n\n\n\n\nThis post details our research on potential datasets\n\n\n\n\n\nOct 11, 2024\n\n\nGroup 2\n\n\n\n\n\n\n\n\n\n\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nGetting started\n\n\n\n\n\n\n\n\nDirections to set up your website and create your first post. \n\n\n\n\n\nFeb 23, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Team Meeting\n\n\n\n\n\n\n\n\nThis post details the steps you’ll take for your first team meeting. \n\n\n\n\n\nFeb 21, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-11-11-fifth-post/fifth_post.html",
    "href": "posts/2024-11-11-fifth-post/fifth_post.html",
    "title": "Fifth Post",
    "section": "",
    "text": "Finding and implementing another dataset:\nhttps://www.kaggle.com/datasets/asaniczka/san-francisco-police-stop-data-2018-2023 This dataset sourced from kaggle, contains detailed records of the police stops conducted in San Francisco over the last 5 years. It includes information such as the location, reason for stop and races that we need to make the comparative analysis.\nThe entire database containing traffic data for all regions across the nation can be found here: https://openpolicing.stanford.edu/data/\nTo incorporate a wider range of data for the purpose of our study, we wanted to bring in traffic stop data from other locations beyond Rhode Island. By looking at traffic data from other states across the country, we can see whether the trends observed in Rhode Island are specific to the area or not. To this end, we will incorporate a similar police stop data set, this time from San Francisco. Studying a dataset from California will allow us to compare East Coast trends against West Coast trends.\nAlthough the dataset is similar in format to the Rhode Island one (being sourced from the same Stanford Policing Project) it will require a significant amount of cleaning to be utilized for several reasons. First, the San Francisco data lists the stop duration variable as a continuous numeric value, recording the precise duration of the stop instead of discrete bins as in the Rhode Island data. In addition, the San Francisco data includes a numeric code for their categorical variables such as ‘action taken,’ ‘reason for stop’ and ‘result of stop.’ We will need to do significant translating of the row values, column names, and column types in order to make the two datasets compatible with each other.\nHere is what the raw dataset looks like:\n\nreadRDS(here::here(\"dataset\", \"sf_raw_dataset.rds\"))|&gt;\n  head(10)\n\n   raw_row_number       date      time                  location      lat\n1          869921 2014-08-01   60 secs      MASONIC AV & FELL ST 37.77300\n2          869922 2014-08-01   60 secs             GEARY&10TH AV 37.78090\n3          869923 2014-08-01  900 secs       SUTTER N OCTAVIA ST 37.78692\n4          869924 2014-08-01 1080 secs         3RD ST & DAVIDSON 37.74638\n5          869925 2014-08-01 1140 secs DIVISADERO ST. & BUSH ST. 37.78635\n6          869926 2014-08-01 1800 secs     3RD ST AND GALVEZ AVE 37.74108\n7          869927 2014-08-01 1800 secs     COLUMBUS AND BROADWAY 37.79787\n8          869928 2014-08-01 2100 secs         INGALLS & QUESADA 37.72912\n9          869929 2014-08-01 3600 secs       17TH ST & BRYANT ST 37.76432\n10         869930 2014-08-01 3600 secs  FULTON ST. & FUNSTON AV. 37.77317\n         lng district subject_age           subject_race subject_sex      type\n1  -122.4459     &lt;NA&gt;          NA asian/pacific islander      female vehicular\n2  -122.4686     &lt;NA&gt;          NA                  black        male vehicular\n3  -122.4267     &lt;NA&gt;          NA               hispanic        male vehicular\n4  -122.3920     &lt;NA&gt;          NA               hispanic        male vehicular\n5  -122.4400     &lt;NA&gt;          NA                  white        male vehicular\n6  -122.3884     &lt;NA&gt;          NA                  black        male vehicular\n7  -122.4067     &lt;NA&gt;          NA               hispanic        male vehicular\n8  -122.3840     &lt;NA&gt;          NA                  black      female vehicular\n9  -122.4104     &lt;NA&gt;          NA                  black        male vehicular\n10 -122.4713     &lt;NA&gt;          NA                  white      female vehicular\n   arrest_made citation_issued warning_issued  outcome contraband_found\n1        FALSE           FALSE           TRUE  warning               NA\n2        FALSE            TRUE          FALSE citation               NA\n3        FALSE            TRUE          FALSE citation               NA\n4        FALSE           FALSE           TRUE  warning               NA\n5        FALSE            TRUE          FALSE citation               NA\n6        FALSE            TRUE          FALSE citation               NA\n7        FALSE            TRUE          FALSE citation               NA\n8        FALSE            TRUE          FALSE citation               NA\n9        FALSE            TRUE          FALSE citation               NA\n10       FALSE            TRUE          FALSE citation               NA\n   search_conducted search_vehicle search_basis\n1             FALSE          FALSE         &lt;NA&gt;\n2             FALSE          FALSE         &lt;NA&gt;\n3             FALSE          FALSE         &lt;NA&gt;\n4             FALSE          FALSE         &lt;NA&gt;\n5             FALSE          FALSE         &lt;NA&gt;\n6             FALSE          FALSE         &lt;NA&gt;\n7             FALSE          FALSE         &lt;NA&gt;\n8             FALSE          FALSE         &lt;NA&gt;\n9             FALSE          FALSE         &lt;NA&gt;\n10            FALSE          FALSE         &lt;NA&gt;\n                             reason_for_stop raw_search_vehicle_description\n1  Mechanical or Non-Moving Violation (V.C.)                      No Search\n2  Mechanical or Non-Moving Violation (V.C.)                      No Search\n3  Mechanical or Non-Moving Violation (V.C.)                      No Search\n4  Mechanical or Non-Moving Violation (V.C.)                      No Search\n5  Mechanical or Non-Moving Violation (V.C.)                      No Search\n6  Mechanical or Non-Moving Violation (V.C.)                      No Search\n7                           Moving Violation                      No Search\n8  Mechanical or Non-Moving Violation (V.C.)                      No Search\n9  Mechanical or Non-Moving Violation (V.C.)                      No Search\n10                          Moving Violation                      No Search\n   raw_result_of_contact_description\n1                            Warning\n2                           Citation\n3                           Citation\n4                            Warning\n5                           Citation\n6                           Citation\n7                           Citation\n8                           Citation\n9                           Citation\n10                          Citation\n\n\nSo far, our work to implement the SF data set into our RI one can be found in scripts/load_and_clean_data2. A preview of the code can be found below:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)\n\n# Load data\nri_traffic_data_clean &lt;- readRDS(here::here(\"dataset\", \"cleaned_dataset.rds\"))\nsf_traffic_data &lt;- readRDS(here::here(\"dataset\", \"sf_raw_dataset.rds\"))\n\n# variables in RI data\n# stop_date, stop_time, driver_gender, driver_race, violation_raw, violation\n# search_conducted, search_type, stop_outcome, is_arrested, stop_duration\n# drugs_related_stop, district\n\nri_traffic_data_clean = ri_traffic_data_clean|&gt;\n  mutate(state = \"Rhode Island\",\n         driver_race = tolower(driver_race))\n\n# omitted columns are already in the dataset correctly labeled\nsf_traffic_data_clean = sf_traffic_data|&gt;\n  filter(!is.na(subject_sex) | \n         !is.na(subject_race))|&gt;\n  mutate(state = \"California\",\n         stop_date = date,\n         stop_time = time,\n         driver_gender = if_else(subject_sex == 'male', 'M', 'F'),\n         driver_race = if_else(subject_race == 'asian/pacific islander', 'asian', subject_race),\n         violation_raw = NULL, # differing values\n         violation = NULL, # differing values\n         search_type = NULL, # not included\n         stop_outcome = NULL, # differing values\n         is_arrested = arrest_made,\n         stop_duration = NULL, # not included,\n         drugs_related_stop = NULL, # not included,\n         )"
  },
  {
    "objectID": "posts/2024-11-4-fourth-post/linear-model.html",
    "href": "posts/2024-11-4-fourth-post/linear-model.html",
    "title": "Fourth Post",
    "section": "",
    "text": "During the fourth week, we were able to further explore the data to unlock new findings. We decided to conduct a general linear model test to understand the correlation between race and arrest while controlling for stop date, gender, and district.\nModel Overview: The logistic regression model was built to investigate the correlation between several predictor variables and the likelihood of arrest during traffic stops. The predictors included driver race, stop date, driver gender, and district. The response variable (is_arrested) is binary, indicating whether an arrest occurred.\nModel Formula: logit(P(is_arrested = 1)) = β0 + β1 (driver_race) + β2 (stop_date) + β3(driver_gender) + β4(district)\n\nFindings: 1. Intercept: The negative coefficient of the intercept (-1.605) suggests that, when all other predictors are at their baseline (e.g., driver race as a reference category, date at zero, driver gender as female, etc.), the log-odds of an arrest are negative, implying a low baseline probability of arrest.\n\nDriver Race:\n\n\n\nBlack Drivers: The coefficient (1.218, p &lt; 0.001) indicates a significant positive association between being a Black driver and the likelihood of arrest. This suggests that Black drivers are more likely to be arrested compared to the baseline race category.\nHispanic Drivers: The coefficient (1.262, p &lt; 0.001) also shows a significant positive correlation, implying that Hispanic drivers face a similarly increased likelihood of arrest.\nWhite Drivers: The coefficient (0.361, p &lt; 0.05) indicates a smaller but still significant positive relationship compared to the baseline.\nOther: The negative coefficient (-0.976, p &gt; 0.05) suggests a reduced likelihood of arrest for drivers in the “Other” race category, but this finding is not statistically significant.\n\n\nStop Date:\nThe small negative coefficient (-0.000195, p &lt; 0.001) for stop_date indicates a slight but statistically significant decrease in the likelihood of arrest over time.\nDriver Gender:\nMale Drivers: The positive coefficient (0.220, p &lt; 0.001) implies that male drivers have a significantly higher chance of arrest compared to female drivers.\nDistricts:\nDistricts K2, K3, X3, and X4 have significant positive coefficients, suggesting these zones are associated with a higher likelihood of arrest. District X1 does not show a significant effect on the arrest likelihood.\n\nStatistical Significance:\nThe model’s p-values indicate that most of the predictors are statistically significant (p &lt; 0.05), except for the driver_race Other and districtZone X1, which do not provide strong evidence of association with the response variable.\nModel Performance:\n- AIC (25801): The Akaike Information Criterion (AIC) suggests how well the model fits the data, with a lower value indicating a better fit. - Residual Deviance (25777) vs. Null Deviance (26583): The reduction in deviance demonstrates that the model explains more variance in the response variable compared to an intercept-only model.\nInterpretation:\nThe analysis suggests that race and gender are significant predictors of arrest during traffic stops, with Black and Hispanic drivers having a notably higher likelihood of arrest than other groups. The model also highlights geographical differences, with certain districts being more prone to arrests than others."
  },
  {
    "objectID": "posts/2024-10-25-third-post/third post.html",
    "href": "posts/2024-10-25-third-post/third post.html",
    "title": "Third Post",
    "section": "",
    "text": "During the third week, we started drafting our data.qmd page for the final project. We described where we found our dataset and why the data was collected. We also described all the variables in our dataset. \nThe dataset we used can be found at https://www.kaggle.com/datasets/mustafaadelibrahim/traffic-stops-in-rhode-islandpolicing-activities?resource=download. The dataset on traffic stops in Rhode Island is part of a larger collection by the Stanford Open Policing Project. This project aims to collect and standardize data on vehicle and pedestrian stops across 31 U.S. states, gathering over 200 million records to promote transparency and accountability in policing. The data was curated by a team of researchers and journalists at Stanford University, blending statistical analysis with data journalism.\nThe dataset had 15 variables: state, stop_date, stop_time, county_name, driver_gender, driver_race, violation_description, violation, search_conducted, search_type, stop_outcome, is_arrested, stop_duration, drugs_related_stop, and district. This data set only focused on Rhode Island so the state was irrelevant. Stop_date and stop_time stated the date and time of day that the traffic stop occurred. The county_name was an empty column. Driver_gender and driver_race detailed the gender and race of the driver who was stopped. The variable violation gave a general classification for the violation while violation_description gave a more detailed description of the reason for the traffic stop. Search_conducted (boolean), search_type, stop_outcome, is_arrested (boolean), stop_duration, drugs_related_stop (boolean) gave more details as to what occurred during the traffic stop which gives us a better idea for the severity of the traffic violation. \nIn the ”data.qmd” file, we included at the bottom some initial analysis and visualization of the distribution of traffic stops by race. You can find a bar plot and table summary showing how many stops are in the data set across each particular race. Although it may be skewed by the population proportions for each race, we can see that whites are stopped most frequently, then blacks, then hispanics, then asians."
  },
  {
    "objectID": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "href": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "title": "First Team Meeting",
    "section": "",
    "text": "These are the steps that you will take today to get started on your project. Today, you will just be brainstorming, and then next week, you’ll get started on the main aspects of the project.\n\nStart by introducing yourselves to each other. I also recommend creating a private channel on Microsoft Teams with all your team members. This will be a place that you can communicate and share ideas, code, problems, etc.\nDiscuss what aspects of the project each of you are more or less excited about. These include\n\nCollecting, cleaning, and munging data ,\nStatistical Modeling,\nVisualization,\nWriting about analyses, and\nManaging and reviewing team work.\n\nBased on this, discuss where you feel your strengths and weaknesses might be.\nNext, start brainstorming questions you hope to answer as part of this project. This question should in some way be addressing issues around racial disparities. The questions you come up with should be at the level of the question we started with when exploring the HMDA data. (“Are there differences in the ease of securing a loan based on the race of the applicant?”) You’ll revise your questions a lot over the course of the project. Come up with a few questions that your group might be interested in exploring.\nBased on these questions, start looking around for data that might help you analyze this. If you are looking at U.S. based data, data.gov is a good source and if you are looking internationally, I recommend checking out the World Bank. Also, try Googling for data. Include “data set” or “dataset” in your query. You might even include “CSV” or some other format. Using “data” by itself in your query often doesn’t work too well. Spend some time searching for data and try to come up with at least three possible data sets. (For your first blog post, you’ll write short proposals about each of them that I’ll give feedback on.)\nCome up with a team name. Next week, I’ll provide the Github Classroom assignment that will be where you work on your final project and you’ll have to have your team name finalized by then. Your project will be hosted online at the website with a URL like sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME.\n\nNext time, you’ll get your final project website set up and write your first blog post."
  },
  {
    "objectID": "posts/2023-10-15-getting-started/getting-started.html",
    "href": "posts/2023-10-15-getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Below, the items marked with [[OP]] should only be done by one person on the team.\n\nTo get started\n\n[[OP]] One person from the team should click the Github Classroom link on Teams.\n[[OP]] That person types in the group name for their group.\nThe rest of the team now clicks the Github Classroom link and selects their team from the dropdown list.\nFinally, each of you can clone the repository to your laptop like a normal assignment.\n\n\n\nSetting up the site\n\n[[OP]] Open the terminal and run quarto publish gh-pages.\n[[OP]] Select Yes to the prompt:  ? Publish site to https://sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME/ using gh-pages? (Y/n)\n[[OP]] Wait for the process to finish.\nOnce it is done, you can go to the URL it asked you about to see your site.\n\nNote: This is the process you will use every time you want to update your published site. Make sure to always follow the steps below for rendering, previewing, and committing your changes before doing these publish steps. Anyone can publish in the future.\n\n\nCustomize your site\n\n[[OP]] Open the _quarto.yml file and update the title to include your team name.\n[[OP]] Go to the about.qmd and remove the TF’s and professor’s names.\nadd your own along with a short introduction and a link to your Github user page.\n[[OP]] Render the site.\n[[OP]] Check and make sure you didn’t get any errors.\n[[OP]] Commit your changes and push.\n[[OP]] Repeat the steps under Setting up your site.\n\nOnce one person is done with this, each teammate in the group can, in turn, repeat steps 3-7. Before doing so, make sure to pull the changes from teammates before starting to make new changes. (We’ll talk soon about ways to organize your work and resolve conflicts.)\n\n\nStart your first post\n\nTo start your first post first, run remotes::install_github(\"sussmanbu/quartopost\") in your Console.\n[[OP]] Run quartopost::quartopost() (or click Addins-&gt;Create Quarto Post, or use C-Shift-P, type “Create Quarto” and press enter to run the command).\n\nNow you can start working on your post. You’ll want to render your post to see what it will look like on the site.\n\nEvery time you want to make a new post, you can repeat step 2 above.\nWhen you want to publish your progress, follow steps 4-7 from Customize your site.\n\nFinally, make sure to read through everything on this site which has the directions and rubric for the final project."
  },
  {
    "objectID": "posts/2024-11-18-sixth-post/sixthpost.html",
    "href": "posts/2024-11-18-sixth-post/sixthpost.html",
    "title": "Sixth Post",
    "section": "",
    "text": "This week we finished implementing the data from San Francisco into our data set. In addition, we performed preliminary EDA on the San Francisco data by implementing the visualization and modeling methods used earlier. The complete data set with both the SF and RI data is generated through \"load_and_clean_data2.R\"\n\nsource(\"scripts/load_and_clean_data2.R\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nJoining with `by = join_by(stop_date, stop_time, driver_gender, driver_race, violation, search_conducted, search_type, stop_outcome, is_arrested, stop_duration, drugs_related_stop, district, state)`\n\nfull_traffic_data_clean|&gt;\n  head(10)\n\n# A tibble: 10 × 13\n   stop_date  stop_time driver_gender driver_race violation search_conducted\n   &lt;date&gt;     &lt;chr&gt;     &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;     &lt;lgl&gt;           \n 1 2005-01-04 12:55:00  M             white       Equipment FALSE           \n 2 2005-01-23 23:15:00  M             white       Speeding  FALSE           \n 3 2005-02-17 04:15:00  M             white       Speeding  FALSE           \n 4 2005-02-20 17:15:00  M             white       Other     FALSE           \n 5 2005-02-24 01:20:00  F             white       Speeding  FALSE           \n 6 2005-03-14 10:00:00  F             white       Speeding  FALSE           \n 7 2005-03-29 21:55:00  M             white       Speeding  FALSE           \n 8 2005-04-04 21:25:00  M             white       Speeding  FALSE           \n 9 2005-07-14 11:20:00  F             white       Speeding  FALSE           \n10 2005-07-14 19:55:00  M             white       Speeding  FALSE           \n# ℹ 7 more variables: search_type &lt;chr&gt;, stop_outcome &lt;chr&gt;, is_arrested &lt;lgl&gt;,\n#   stop_duration &lt;chr&gt;, drugs_related_stop &lt;lgl&gt;, district &lt;chr&gt;, state &lt;chr&gt;\n\n\nBelow, you can see our code for modeling the likelihood of arrest by certain factors for our SF data alone. We can observe a noticeable difference in this model’s performance compared to the RI model; Race does not play as significant a role in predicting the probability of arrest here.\n\nmodel &lt;- glm(is_arrested ~ driver_race + driver_gender + stop_date + district,\n             data = sf_traffic_data_clean, \n             family = binomial)\nsummary(model)\n\n\nCall:\nglm(formula = is_arrested ~ driver_race + driver_gender + stop_date + \n    district, family = binomial, data = sf_traffic_data_clean)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)         -8.692e-01  1.624e-01  -5.351 8.73e-08 ***\ndriver_raceblack     1.078e+00  3.541e-02  30.432  &lt; 2e-16 ***\ndriver_racehispanic  8.353e-01  3.741e-02  22.329  &lt; 2e-16 ***\ndriver_raceother     1.176e-01  4.504e-02   2.610 0.009058 ** \ndriver_racewhite     2.818e-01  3.383e-02   8.330  &lt; 2e-16 ***\ndriver_genderM       4.391e-01  2.314e-02  18.979  &lt; 2e-16 ***\nstop_date           -3.027e-04  1.026e-05 -29.496  &lt; 2e-16 ***\ndistrictB            7.260e-02  4.985e-02   1.456 0.145320    \ndistrictC            1.405e-01  4.904e-02   2.865 0.004167 ** \ndistrictD            6.713e-01  4.678e-02  14.352  &lt; 2e-16 ***\ndistrictE            2.036e-01  5.176e-02   3.933 8.38e-05 ***\ndistrictF            9.373e-02  5.664e-02   1.655 0.097986 .  \ndistrictG            3.370e-01  5.168e-02   6.521 6.99e-11 ***\ndistrictH            3.756e-01  4.690e-02   8.009 1.15e-15 ***\ndistrictI            1.855e-01  5.032e-02   3.687 0.000227 ***\ndistrictJ            3.987e-01  5.448e-02   7.317 2.53e-13 ***\ndistrictK           -8.336e-01  5.027e-01  -1.658 0.097306 .  \ndistrictS            3.346e-01  4.520e-01   0.740 0.459149    \ndistrictT            9.274e-01  5.083e-01   1.824 0.068095 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 121691  on 852882  degrees of freedom\nResidual deviance: 117985  on 852864  degrees of freedom\n  (52187 observations deleted due to missingness)\nAIC: 118023\n\nNumber of Fisher Scoring iterations: 7\n\nexp(coef(model))\n\n        (Intercept)    driver_raceblack driver_racehispanic    driver_raceother \n          0.4192828           2.9380292           2.3054834           1.1247418 \n   driver_racewhite      driver_genderM           stop_date           districtB \n          1.3254798           1.5512986           0.9996973           1.0753016 \n          districtC           districtD           districtE           districtF \n          1.1508465           1.9568498           1.2257600           1.0982603 \n          districtG           districtH           districtI           districtJ \n          1.4007383           1.4558570           1.2038369           1.4898221 \n          districtK           districtS           districtT \n          0.4345004           1.3973248           2.5279065 \n\n\nFindings:\n\nIntercept: The negative coefficient for the intercept (-8.692e-01) indicates that when all predictors are at their baseline (e.g., driver race as a reference category, stop date at zero, and driver gender as female), the log-odds of an arrest are negative, suggesting a lower baseline probability of arrest.\nDriver Race: \n\nBlack Drivers: The coefficient (1.078e+00, p &lt; 0.001) shows a significant positive association between being a Black driver and the likelihood of arrest, indicating a higher likelihood compared to the baseline race category.\nHispanic Drivers: The coefficient (8.353e-01, p &lt; 0.001) also shows a significant positive association, suggesting that Hispanic drivers are more likely to be arrested than the baseline race category. \nWhite Drivers: The coefficient (2.818e-01, p &lt; 0.001) suggests a smaller, but still significant, positive association with the likelihood of arrest. \nOther Race: The coefficient (1.176e-01, p = 0.009058) suggests a modest but significant positive relationship with arrest likelihood.\n\nDriver_gender: The positive coefficient (4.391e-01, p &lt; 0.001) indicates that male drivers are significantly more likely to be arrested than female drivers.\n\nStop_dates: The small negative coefficient (-3.027e-04, p &lt; 0.001) suggests that the likelihood of arrest slightly decreases over time, a statistically significant trend.\n\nDistricts: Districts C, D, G, H, and J have significant positive coefficients, suggesting these zones are associated with a higher likelihood of arrest. Districts B, S, and T do not show a statistically significant effect on the arrest likelihood, as indicated by their higher p-values. District K shows a negative coefficient, but it is not statistically significant, indicating no strong evidence of reduced arrest likelihood.\n\nStatistical Significance:\nThe model’s p-values show that most predictors, including race (Black, Hispanic, White), gender, stop date, and certain districts (C, D, G, H, J), are statistically significant (p &lt; 0.05), indicating they have significant relationships with the likelihood of arrest. However, predictors such as districts B, S, T, and K are not statistically significant, suggesting no strong evidence of their association with the response variable.\n\nModel Performance:\n\nModel Performance: AIC (118023): The Akaike Information Criterion indicates the model’s fit, with a lower value suggesting a better fit. \nNull Deviance: 121691 Residual Deviance: 117985 The reduction in deviance demonstrates that the model explains more variance in the response variable compared to an intercept-only model.\n\nInterpretation:\nThis analysis suggests that race and gender remain significant predictors of arrest during traffic stops. Specifically: Black and Hispanic drivers are significantly more likely to be arrested. Male drivers have a higher likelihood of arrest compared to female drivers. The model also reveals district-level differences, with certain districts such as Districts D, G, and H having a stronger association with arrests, while others show a weaker or no significant association. Stop date trends suggest a slight decrease in arrest likelihood over time.\nBelow are some graphs to visualize the raw San Francisco data. As seen below, this data includes a much larger proportion of black and hispanic drivers compared to the RI data, and Blacks seem to be given warnings with a slightly higher proportion than other races:\n\narrest_rates &lt;- sf_traffic_data_clean %&gt;%\n  group_by(driver_race) %&gt;%\n  summarize(arrest_rate = mean(is_arrested, na.rm = TRUE)) \n\nggplot(arrest_rates, aes(x = factor(driver_race), y = arrest_rate, fill = factor(driver_race))) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Arrest Rate by Race\", x = \"Race\", y = \"Arrest Rate\") +\n  scale_y_continuous(labels = scales::percent) +    theme_minimal()\n\n\n\n\n\n\n\nrace_stop_counts &lt;- sf_traffic_data %&gt;%\n  count(subject_race, raw_result_of_contact_description)\n\nggplot(race_stop_counts, aes(x = factor(subject_race), y = n, fill = raw_result_of_contact_description)) +\n  geom_bar(stat = \"identity\", position = \"fill\") + \n  labs(title = \"Distribution of Stop Results by Race\", x = \"Race\", y = \"Proportion\") +\n  scale_y_continuous(labels = scales::percent) + theme_minimal()"
  },
  {
    "objectID": "posts/2024-10-18-second-post/second post.html",
    "href": "posts/2024-10-18-second-post/second post.html",
    "title": "Second Post",
    "section": "",
    "text": "During the second week, we decided to use our first dataset for the final project–The Rhode Island traffic stop dataset. We believe that this dataset will allow us to investigate most effectively certain racial disparities that may exist in traffic law enforcement. The dataset is sourced from Kaggle, and was collected by the Standford Open Police Project to investigate policing patterns.\nResearch questions to consider with this dataset:\n\nDoes race impact the duration of stop and the extent of search?\nWhat is the most common reason for stops?\nDoes the proportion of drug-related stops to total stops vary significantly between races?\nDoes the proportion of drug-related stops to total stops vary significantly between races?\nIs there a correlation between race and stop_outcome = arrest?\nWhat is the distribution of stops in districts in terms of race?\nWhat is the probability a search is conducted depending on the race?\nControlling for stop date, gender, and district, what’s the correlation between race and arrest?\n\nWe also did some basic data cleaning, which involves uploading the data and taking out empty rows. We also removed the county and state column because the county values were all null and the entire dataset is collected from Rhode Island. We also modified the stop_time variable to the actual time of day, instead of seconds into the day, making it easier to read. Here is the code for all the modification:\n\n# Load packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)\n\n# Load data\ntraffic_data &lt;- read_csv(here::here(\"dataset\", \"Traffic stops in Rhode Island.csv\"))\n\nRows: 91741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): state, driver_gender, driver_race, violation_raw, violation, searc...\nlgl  (4): county_name, search_conducted, is_arrested, drugs_related_stop\ndate (1): stop_date\ntime (1): stop_time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Clean data\ntraffic_data_cleaned &lt;- traffic_data %&gt;%\n  filter(!is.na(driver_race) & \n           !is.na(driver_gender) & \n           !is.na(violation_raw) & \n           !is.na(violation) & \n           !is.na(search_conducted) & \n           !is.na(stop_outcome) & \n           !is.na(stop_duration) & \n           !is.na(drugs_related_stop)) %&gt;%\n  select(-state, -county_name)\n\n# Change stop_time to numeric\ntraffic_data_cleaned$stop_time &lt;- as.numeric(traffic_data_cleaned$stop_time)\n\n\n# Function to convert sec to time of day\nsecs_to_time_of_day &lt;- function(seconds) {\n  hours &lt;- (seconds %/% 3600) %% 24\n  minutes &lt;- (seconds %/% 60) %% 60\n  secs &lt;- seconds %% 60\n  sprintf(\"%02d:%02d:%02d\", hours, minutes, secs)\n}\n\n# Apply conversion function\ntraffic_data_cleaned$stop_time &lt;- sapply(traffic_data_cleaned$stop_time, secs_to_time_of_day)\n\n# Save cleaned data as an .rds file\n# How to call data later: cleaned_data &lt;- read_rds(here::here(\"dataset\", \"cleaned_dataset.rds\"))\nsaveRDS(traffic_data_cleaned, here::here(\"dataset\", \"cleaned_dataset.rds\"))"
  },
  {
    "objectID": "posts/2024-10-24-first-post/First Post.html",
    "href": "posts/2024-10-24-first-post/First Post.html",
    "title": "First Post",
    "section": "",
    "text": "#Data set 1:\nLink to dataset: https://www.kaggle.com/datasets/mustafaadelibrahim/traffic-stops-in-rhode-islandpolicing-activities?resource=download\nThe dataset of traffic stops by police officers was collected by the Stanford Open Policing Project. It has 15 columns and 91741 rows. Through using this data, we hope to investigate if the driver’s race is correlated with the amount and severity of the stop. Therefore in terms of data cleaning, we might focus on the variables driver_race, search_conducted, stop_outcome, stop_duration, and is_arrested.\n#Data set 2\nLink to data set: https://catalog.data.gov/dataset/alzheimers-disease-and-healthy-aging-data/resource/b2443e45-68aa-4004-b97a-e62c4c28502f\nThe Alzheimer’s data set includes 284142 rows by 31 columns. The data set reports the number of people of certain age groups and races that were observed to have Alzheimer’s within a specified period of time, and records other information such as health condition and medical history. With this data set, we can study a potential racial disparity in the number of people that suffer from Alzheimer’s. The data set is sourced from the Department of Health and Human Services, and was published by the Center for Disease Control and Prevention. The data was collected over the period of 2015 to 2022. The data can be easily loaded as it is stored simply in a CSV file. Some cleaning may be necessary as there are many variables that may be extraneous to our study, such as geographic location. In addition, there are many rows where some data entries are missing, and they will have to be cleaned out.\n#Data set 3\nLink to data set: https://www.kaggle.com/datasets/arashnic/covid19-case-surveillance-public-use-dataset\nThe COVID-19 case surveillance system database includes individual-level data reported to U.S. states and autonomous reporting entities, including New York City and the District of Columbia (D.C.), as well as U.S. territories and states. On April 5, 2020, COVID-19 was added to the Nationally Notifiable Condition List and classified as “immediately notifiable, urgent (within 24 hours)” by a Council of State and Territorial Epidemiologists (CSTE) Interim Position Statement (Interim-20-ID-01). CSTE updated the position statement on August 5, 2020 to clarify the interpretation of antigen detection tests and serologic test results within the case classification. Through comparing (hosp_yn, icu_yn, death_yn) in different racial groups, we are trying to analyze any disparities or variations. There are also many rows where some data entries are missing, and we will work to clean them out."
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html",
    "href": "posts/2023-12-20-examples/examples.html",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "href": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team TEAMNAME. The members of this team are below."
  },
  {
    "objectID": "about.html#nathaniel-pulosne",
    "href": "about.html#nathaniel-pulosne",
    "title": "About",
    "section": "Nathaniel Pulosne",
    "text": "Nathaniel Pulosne\nNathan is a Junior undergrad in math/statistics from Boston."
  },
  {
    "objectID": "about.html#sindhuja-kumar",
    "href": "about.html#sindhuja-kumar",
    "title": "About",
    "section": "Sindhuja Kumar",
    "text": "Sindhuja Kumar\nSindhuja is Senior undergrad in Data Science from Pittsburgh, PA."
  },
  {
    "objectID": "about.html#jason-zhu",
    "href": "about.html#jason-zhu",
    "title": "About",
    "section": "Jason Zhu",
    "text": "Jason Zhu\nJason is a Senior undergrad in Computer Science/Statistics from New York."
  },
  {
    "objectID": "about.html#shiqin-song",
    "href": "about.html#shiqin-song",
    "title": "About",
    "section": "Shiqin Song",
    "text": "Shiqin Song\nSong is a Senior undergrad major in Applied Math from China"
  },
  {
    "objectID": "about.html#katrina-deng",
    "href": "about.html#katrina-deng",
    "title": "About",
    "section": "Katrina Deng",
    "text": "Katrina Deng\nKatrina is a Junior undergrad in Psychology/Statistics from Vancouver, Canada\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "This comes from the file big_picture.Rmd.\nThink of this page as your 538/Upshot style article. This means that you should try to tell a story through the data and your analysis. Read articles from those sites and similar sites to get a feeling for what they are like. Try to write in the style of a news or popular article. Importantly, this page should be geared towards the general public. You shouldn’t assume the reader understands how to interpret a linear regression or a complicated plot. Focus on interpretation and visualizations."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a story. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nInteractive component\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions?\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  }
]